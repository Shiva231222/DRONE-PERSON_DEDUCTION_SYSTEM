# -*- coding: utf-8 -*-
"""DORN DEDUCTION.PY

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14m3OYytzu4_hOKV5h_X_3paCew8e5RH1

# AI-BASED DRONE DETECTION SYSTEM

# TECHNOLOGIES USED

Python

OpenCV

PyTorch

YOLOv5 (Real-time detection)

Faster R-CNN (High accuracy detection)

CNN (Basic custom model)

 COCO / Custom Drone Dataset
"""

import torch
import cv2

# Load YOLOv5 pretrained model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# Load image / video
cap = cv2.VideoCapture("drone_video.mp4")  # or 0 for webcam

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Inference
    results = model(frame)

    # Render results
    frame = results.render()[0]

    cv2.imshow("Drone Detection - YOLOv5", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

import torch
import torchvision
import cv2
from torchvision import transforms
import requests
import numpy as np

# Load Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

transform = transforms.Compose([transforms.ToTensor()])

# Corrected way to load an image from a URL
# Replace with a direct image URL (e.g., from Pexels, right-click 'Copy Image Address')
image_url = "https://images.pexels.com/photos/1763075/pexels-photo-1763075.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1" # Example direct image URL

try:
    response = requests.get(image_url, stream=True)
    response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
    image_array = np.asarray(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)

    if image is None:
        raise ValueError("Could not decode image from URL.")

    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    input_tensor = transform(img_rgb).unsqueeze(0)

    with torch.no_grad():
        predictions = model(input_tensor)

    # Convert tensor to numpy array for drawing
    output_image = image.copy()

    # Filter predictions to only show 'person' (COCO class ID 0) for example,
    # as Faster R-CNN on COCO is not trained for 'drone'.
    # For actual drone detection, you'd need a model trained on drones.
    coco_labels = [
        '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',
        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
        'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A',
        'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
        'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
        'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
        'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',
        'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',
        'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock',
        'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
    ]

    for box, label, score in zip(predictions[0]['boxes'], predictions[0]['labels'], predictions[0]['scores']):
        if score > 0.7: # Confidence threshold
            x1, y1, x2, y2 = map(int, box)
            class_name = coco_labels[label.item()] # Get class name
            cv2.rectangle(output_image, (x1,y1), (x2,y2), (0,255,0), 2)
            cv2.putText(output_image, f"{class_name}: {score:.2f}", (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)

    # Display the image (Note: This will typically only work in environments with a GUI,
    # or save the image to a file in Colab).
    # For Colab, you can display the image using matplotlib or save it.
    # For simplicity, let's save the image.
    cv2.imwrite("detected_objects_faster_rcnn.jpg", output_image)
    print("Detected objects image saved as detected_objects_faster_rcnn.jpg")

except requests.exceptions.RequestException as e:
    print(f"Error downloading image: {e}")
except ValueError as e:
    print(f"Error processing image: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

# cv2.imshow("Drone Detection - Faster R-CNN", image)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

import tensorflow as tf
from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

cap = cv2.VideoCapture(0)

cap

!pip install playsound
import torch
import cv2
from playsound import playsound
import threading

# Load YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

cap = cv2.VideoCapture(0)  # webcam

def play_alert():
    playsound("alert.mp3")

alert_triggered = False

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame)

    for *box, conf, cls in results.xyxy[0]:
        if conf > 0.6:   # confidence threshold
            if not alert_triggered:
                threading.Thread(target=play_alert).start()
                alert_triggered = True

            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,0,255), 2)
            cv2.putText(frame, "ðŸš¨ DRONE DETECTED",
                        (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.9, (0,0,255), 2)

    cv2.imshow("Drone Detection Alert System", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()